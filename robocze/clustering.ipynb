{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading dataset\n",
    "data = pd.read_csv('D:\\Studia\\inz\\datasets\\iris\\iris_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = data.iloc[:, :4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_target = data.iloc[:, 4].to_numpy\n",
    "data_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datanpy = data_num.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = KMeans(n_clusters=number_of_classes*3)\n",
    "clustering.fit(datanpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.array(['red', 'blue', 'green', 'orange', 'darkgray', 'powderblue', 'lightsalmon', 'cyan', 'pink'])\n",
    "plt.scatter(x=datanpy[:,0], y=datanpy[:,1], c=colors[clustering.labels_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_rcv1\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.datasets import fetch_lfw_people\n",
    "#rcv1 = fetch_rcv1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcv1.target_names[:3].tolist()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "data_all, data_label= datasets.load_iris(return_X_y=True)\n",
    "data_all_train, data_all_test, data_label_train, data_label_test = train_test_split(data_all, data_label, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_all_train[:,0], data_all_train[:,2],c=data_label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_all_test[:,0], data_all_test[:,2],c=data_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_all[:,0], data_all[:,2],c=data_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(reduced_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating clusters kmeans\n",
    "number_of_clusters = 15* number_of_classes\n",
    "KMeans()\n",
    "clust= KMeans(n_clusters=number_of_clusters)\n",
    "clust.fit(data_all_train)\n",
    "#print label of clusters\n",
    "print(clust.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create array to group cluster intsnaces\n",
    "clusters = np.array([])\n",
    "for i in clust.labels_:\n",
    "    clusters = np.append(clusters, [i, data_all_train[i]])\n",
    "\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roobczenie nie działą\n",
    "for i in range(number_of_clusters):\n",
    "    if(clusters[0] == i):\n",
    "        print('true')\n",
    "tmp = clusters[clusters[0]==1]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "#creating list grouping idexes of training data grouped by cluster label\n",
    "clusters_with_id = defaultdict(list)\n",
    "for idx, cluster in enumerate(clust.labels_):\n",
    "    clusters_with_id[cluster].append(idx)\n",
    "\n",
    "clusters_with_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_in_cluster(data_all, indexes):\n",
    "    count_of_values = len(indexes)\n",
    "    sum = 0\n",
    "\n",
    "    # liczba wszystkich wymiarów wzgledem których ma być sumowane\n",
    "    count_of_features = data_all[0].shape[0]\n",
    "\n",
    "    median = np.array([])\n",
    "    \n",
    "    for feature in range(count_of_features):\n",
    "        for index in indexes:\n",
    "            actual_data = data_all[index]\n",
    "            sum += actual_data[feature]\n",
    "        median = np.append(median, sum/count_of_values)\n",
    "        sum = 0\n",
    "\n",
    "    return median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clusters_with_id[key-czyli label of cluster :)]\n",
    "#clusters_with_id[6]\n",
    "\n",
    "#utowrzenie tablicy n wartości, gdzie n to liczba klas, w której bedzie trzymana liczba wystapień danej klasy\n",
    "#initialize array with 0 occurrence of each class\n",
    "classes_with_data = [] #zestaw instancji danych dla każdej z klasy tj np classes_data[0] - dane instancji klasy pierwszej w klastrze\n",
    "classes_with_indexes = []\n",
    "#create empty reduced dataset\n",
    "reduced_set = []\n",
    "reduced_data = []\n",
    "\n",
    "classes_count = np.array([])\n",
    "for i in range(number_of_classes):\n",
    "    classes_count = np.append(classes_count, 0)\n",
    "    classes_with_data.append([])\n",
    "    classes_with_indexes.append([])\n",
    "    reduced_set.append([])\n",
    "\n",
    "\n",
    "#dla każdego klastra\n",
    "#for each cluster\n",
    "for i in range(number_of_clusters):\n",
    "    #zliczamy liczbę wystąpień każdej z klas\n",
    "    #dla każdego id wystepującej danej w klastrze sprawdzić klasę i zwiększyć liczbę wystąpień\n",
    "    for instance_id in clusters_with_id[i]:\n",
    "        class_label_of_instance = data_label_train[instance_id]\n",
    "        #to teraz dodajemy do listy danych instancji tej klasy \n",
    "        #classes_data.append(data_all_train[instance_id])\n",
    "        classes_with_data[class_label_of_instance].append(data_all_train[instance_id]) #dodajemy do\n",
    "        #classes_with_data= np.append(classes_with_data[class_label_of_instance], data_all_train(instance_id))\n",
    "        classes_with_indexes[class_label_of_instance].append(instance_id)\n",
    "        classes_count[class_label_of_instance]+=1\n",
    "    print('classes count:',classes_count)\n",
    "    print('classes data with id:',classes_with_indexes)\n",
    "\n",
    "    is_homogeniuos = True\n",
    "    count_of_classes_in_cluster = 0\n",
    "    for i in range(number_of_classes):\n",
    "        if(classes_count[i] > 0):\n",
    "            count_of_classes_in_cluster+=1\n",
    "    if (count_of_classes_in_cluster > 1):\n",
    "        is_homogeniuos = False\n",
    "\n",
    "\n",
    "    if (is_homogeniuos):\n",
    "        print('homogenious')\n",
    "        cm = find_majority_class(number_of_classes, classes_with_indexes)\n",
    "        #obliczyć średnia wszystkich wartości instancji w klastrze w postaci obiektu-\n",
    "        #dla każdej instancji obliczyć odległość euklidesową od tej średniej i zapisać w jakiejś pomocniczej np.array?\n",
    "        #wybrać \n",
    "        mean_point = mean_point_in_cluster(data_all=data_all_train, indexes=clusters_with_id[i])\n",
    "        #print(mean_point)\n",
    "        accept_id = find_id_of_nearest_point(data_all = data_all_train, indexes = clusters_with_id[i], point = mean_point)\n",
    "        #print(accept_id)\n",
    "        reduced_set[cm].append(data_all_train[accept_id])\n",
    "        reduced_data.append(data_all_train[accept_id])\n",
    "        \n",
    "    else:\n",
    "        \"\"\"\n",
    "        TODO \n",
    "        majority_class_label \n",
    "        for i in set of other class \n",
    "            for data with class \n",
    "\n",
    "\n",
    "        robimy liste labeli, sprawdzamy, która jest najczęsciej - ta zapamiętujemy i wywalamy z listy;\n",
    "        dla każdej klasy z listy\n",
    "            dla każdego elementu z tej klasy w tym klastrze\n",
    "                szukamy elementu z klasy głowenj, który jest najbliżej tego - potrzebny tez indeks\n",
    "                szukamy elemntu z tej klasy, który jest najbliżej tego znalezonego z głównej\n",
    "        \"\"\"\n",
    "        #majority class\n",
    "        cm = find_majority_class(number_of_classes, classes_with_indexes)\n",
    "        print(cm)\n",
    "\n",
    "        for class_id in range(number_of_classes):\n",
    "            if class_id == cm:\n",
    "                break\n",
    "            for el in classes_with_indexes[class_id]:\n",
    "                #najbliższy element do badanego spośród głownej klasy\n",
    "                nearest_of_majority_class = find_nearest_instance(element = el, indexes_of_data = classes_with_indexes[cm], data_all = data_all_train)\n",
    "                print('nearest_of_majority_class:',nearest_of_majority_class)\n",
    "                #reduced_set = np.append(reduced_set, data_all_train[nearest_of_majority_class])\n",
    "                reduced_set[cm].append(data_all_train[nearest_of_majority_class])\n",
    "                reduced_data.append(data_all_train[nearest_of_majority_class])\n",
    "                #najbliżsy element do badanego spośród tej samej klasy co badany\n",
    "                nearest_of_actual_class = find_nearest_instance(element = el, indexes_of_data = classes_with_indexes[class_id], data_all = data_all_train)\n",
    "                print('nearest_of_actual_class:', nearest_of_actual_class)\n",
    "                #reduced_set = np.append(reduced_set, data_all_train[nearest_of_actual_class])\n",
    "                reduced_set[cm].append(data_all_train[nearest_of_actual_class])\n",
    "                reduced_data.append(data_all_train[nearest_of_actual_class])\n",
    "\n",
    "\n",
    "        \n",
    "    #reset classes counter     \n",
    "    classes_count = np.array([])\n",
    "    classes_with_data = [] #zestaw instancji danych dla każdej z klasy tj np classes_data[0] - dane instancji klasy pierwszej w klastrze\n",
    "    classes_with_indexes = []\n",
    "    for i in range(number_of_classes):\n",
    "        classes_count = np.append(classes_count, 0)\n",
    "        classes_with_data.append([])\n",
    "        classes_with_indexes.append([])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all_train[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_with_id[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_point_in_cluster(data_all, indexes):\n",
    "    count_of_values = len(indexes)\n",
    "    sum = 0\n",
    "\n",
    "    # liczba wszystkich wymiarów wzgledem których ma być sumowane\n",
    "    count_of_features = data_all[0].shape[0]\n",
    "\n",
    "    mean_point = np.array([])\n",
    "    \n",
    "    for feature in range(count_of_features):\n",
    "        sum = 0\n",
    "        for index in indexes:\n",
    "            actual_data = data_all[index]\n",
    "            sum += actual_data[feature]\n",
    "        mean_point = np.append(mean_point, sum/count_of_values)\n",
    "\n",
    "    return mean_point\n",
    "\n",
    "mean_point_in_cluster(data_all_train, [0,1,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function finding id of point in data, nearest to given point. Using for find nerest point of mean in homogeniuos cluster \n",
    "TODO czy ma zwracać kilka indesów jeżeli takie same odległosci?\n",
    "\"\"\"\n",
    "def find_id_of_nearest_point(data_all, indexes, point):\n",
    "    #id of nearest, for now the first\n",
    "    id = indexes[0] \n",
    "    #minimal distance, for now - the first distance\n",
    "    min_dist = distance.euclidean(point, data_all[id])\n",
    "\n",
    "    for i in indexes:\n",
    "        data = data_all[i]\n",
    "        dist = distance.euclidean(point, data)\n",
    "        if min_dist > dist:\n",
    "            min_dist = dist\n",
    "            id = i\n",
    "\n",
    "    return id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "data_all - data from getting exact\n",
    "indexes - indexes of data from data_all\n",
    "'''\n",
    "def data_for_indexes(data_all, indexes):\n",
    "    data_indexes = np.array([])\n",
    "    for id in indexes:\n",
    "        data_indexes = np.append(data_indexes, data_all[id])\n",
    "\n",
    "    return data_indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function return index of majority class\n",
    "\"\"\"\n",
    "def  find_majority_class(number_of_classes, classes_with_indexes):\n",
    "    max = len(classes_with_indexes[0])\n",
    "    majority_class = 0\n",
    "\n",
    "    for i in range(number_of_classes):\n",
    "        count = len(classes_with_indexes[i])\n",
    "        if max < count:\n",
    "            max = count\n",
    "            majority_class = i\n",
    "\n",
    "    return majority_class\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function return index of nearest instance to given\n",
    "element - index of instance \n",
    "indexes_of_data - indexes of instances from which have to find nearest to element\n",
    "data_all - array of all instances to get data of selected index\n",
    "\"\"\"\n",
    "def  find_nearest_instance(element, indexes_of_data, data_all):\n",
    "    point = data_all[element]\n",
    "    #first temporary index\n",
    "    id = 0\n",
    "    #minimal distance, for now - the first distance\n",
    "    min_dist = distance.euclidean(point, data_all[id])\n",
    "    for i in indexes_of_data:\n",
    "        if i == element:\n",
    "            break\n",
    "        data = data_all[i]\n",
    "        dist = distance.euclidean(point, data)\n",
    "        if min_dist > dist:\n",
    "            min_dist = dist\n",
    "            id = i\n",
    "\n",
    "    return id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#colors = [red, green,blue] \n",
    "scatter = plt.scatter(classes_with_data[0], classes_with_data[1])\n",
    "plt.xlabel('sepal length (cm)')\n",
    "plt.ylabel('sepal width (cm)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_all_train[:,0], data_all_train[:,2],c=data_label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_set.un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_colors = []\n",
    "\n",
    "for i in range(number_of_classes):\n",
    "    for id in reduced_set[i]:\n",
    "        reduced_colors.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data = []\n",
    "for id in range(len(reduced_set)):\n",
    "    for i in range(number_of_classes):\n",
    "        reduced_data.append(reduced_set[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {0:'red',1:'green',2:'blue', 3: 'purple'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(pd_reduced[0], pd_reduced[2], cmap=)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_data = np.unique(reduced_data)\n",
    "reduced_colors = []\n",
    "\n",
    "for i in range(number_of_classes):\n",
    "    for id in reduced_data[i]:\n",
    "        reduced_colors.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.process_time()\n",
    "#knn classify - measure time and accuracy for original train dataset\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(data_all_train,data_label_train)\n",
    "accuracy = knn.score(data_all_test,data_label_test)\n",
    "elapsed = time.process_time() - t\n",
    "\n",
    "print(\"Time:  \", elapsed)\n",
    "print('Accuracy:  ', accuracy)\n",
    "print('Count of instances', len(data_all_train))\n",
    "\n",
    "t = time.process_time()\n",
    "knn2 = KNeighborsClassifier(n_neighbors=5)\n",
    "knn2.fit(np.array(reduced_data),np.array(reduced_colors))\n",
    "accuracy = knn2.score(data_all_test,data_label_test)\n",
    "elapsed = time.process_time() - t\n",
    "\n",
    "print(\"Time:  \", elapsed)\n",
    "print('Accuracy:  ', accuracy)\n",
    "print('Count of instances', len(reduced_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Time:   0.0\nAccuracy:   0.9333333333333333\nCount of instances 105\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-245-b88d12fb9bf7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0msvn2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0msvn2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduced_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduced_colors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvn2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_all_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_label_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0melapsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1130\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m             X, y = self._validate_data(X, y, accept_sparse=\"csr\",\n\u001b[1;32m-> 1132\u001b[1;33m                                        multi_output=True)\n\u001b[0m\u001b[0;32m   1133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    801\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 803\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    804\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    597\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "t = time.process_time()\n",
    "#knn classify - measure time and accuracy for original train dataset\n",
    "from sklearn import svm\n",
    "svn = svm.SVC()\n",
    "svn.fit(data_all_train,data_label_train)\n",
    "accuracy = svn.score(data_all_test,data_label_test)\n",
    "elapsed = time.process_time() - t\n",
    "\n",
    "print(\"Time:  \", elapsed)\n",
    "print('Accuracy:  ', accuracy)\n",
    "print('Count of instances', len(data_all_train))\n",
    "\n",
    "t = time.process_time()\n",
    "svn2 = KNeighborsClassifier(n_neighbors=5)\n",
    "svn2.fit(np.array(reduced_data),np.array(reduced_colors))\n",
    "accuracy = svn2.score(data_all_test,data_label_test)\n",
    "elapsed = time.process_time() - t\n",
    "\n",
    "print(\"Time:  \", elapsed)\n",
    "print('Accuracy:  ', accuracy)\n",
    "print('Count of instances', len(reduced_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1602421846589",
   "display_name": "Python 3.7.7 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}